# -*- coding: utf-8 -*-
"""YoloR2_FishDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yFxrDSklSB2gShMkiEmvq8jyz3OLo6V6

Splitting video frames into images
"""

#Splits according to the frame
import cv2
import os

dir_path = '/content/drive/MyDrive/Fish detection/fishclef_2015/test_set/videos/video_mp4'
k=1
for j in os.listdir(dir_path):

  path = '/content/drive/MyDrive/Fish detection/fishclef_2015/test_set/videos/video_mp4/'+str(j)
  #print(j)
  # Opens the Video file
  cap= cv2.VideoCapture(path)
  i=0
  while(cap.isOpened()):
      ret, frame = cap.read()
      if ret == False:
          break
      cv2.imwrite('/content/drive/MyDrive/Fish detection/test/images/tvid'+str(k)+'_frame'+str(i)+'.jpg',frame)
      #print('/content/drive/MyDrive/Fish detection/test/images/tvid'+str(k)+'_frame'+str(i)+'.jpg')
      i+=1

  cap.release()
  cv2.destroyAllWindows()
  print("Vid"+str(k)+":"+str(i))
  k+=1

import os

# folder path
#dir_path = r'/content/drive/MyDrive/Fish detection/fishclef_2015/training_set/videos/frame_image/video1'
count = 0
dir_path = "/content/drive/MyDrive/Fish detection/test/images/"
# Iterate directory
for path in os.listdir(dir_path):
    # check if current path is a file
    if os.path.isfile(os.path.join(dir_path, path)):
        count += 1
print('File count:', count)

from PIL import Image

for i in range(6):
  im = Image.open('/content/drive/MyDrive/Fish_detection/train/images/vid'+str(i+1)+'_frame10.jpg')
  width, height = im.size
  print(str(i+1)," ",width," ",height)

for i in range(13):
  im = Image.open('/content/drive/MyDrive/Fish_detection/train/images/vid'+str(i+8)+'_frame10.jpg')
  width, height = im.size
  print(str(i+8)," ",width," ",height)

im = Image.open('/content/drive/MyDrive/Fish_detection/valid/images/vid7_frame11.jpg')
width, height = im.size
print(width," ",height)

"""Rename files"""

import os
#main_path = '/content/drive/MyDrive/Fish detection/fishclef_2015/training_set/videos/frame_image'
#for k in os.listdir(main_path):
dir_path = "/content/drive/MyDrive/Fish detection/fishclef_2015/training_set/videos/frame_image/video20"
j=20
k=0
# Absolute path of a file
for i in os.listdir(dir_path):
  old_name = os.path.join(dir_path, i)
  new_name = os.path.join(dir_path, "vid"+str(j)+"_frame"+str(k))
  #temp = os.path.join(dir_path, i)
  print(new_name)
  k += 1
    #print(old_name)
    # Renaming the file
  os.rename(old_name, new_name)
#j+=1

"""Convert xml to txt"""

import glob
import xml.etree.ElementTree as ET

fish_dict = {
        "Dascyllus Reticulatus": 0,
        "Chaetodon Lununatus": 1,
        "Pempheris Vanicolensis": 2,
        "Dascyllus Aruanus": 3,
        "Plectrogly-Phidodon Dickii": 4,
        "Amphiprion Clarkii": 5,
        "Chaetodon Trifascialis": 6,
        "Acanthurus Nigrofuscus": 7,
        "Chromis Chrysura": 8,
        "Hemigumnus Malapterus": 9,
        "Myripristis Kuntee": 10,
        "Chaetodon Speculum": 11,
        "Abudefduf Vaigiensis": 12,
        "Neoglyphidodon Nigroris": 13,
        "Zebrasoma Scopas": 14,
        }

for xml_file in glob.glob("./xml-files/vid1.xml"):
    tree = ET.parse(xml_file)
    vid_num = xml_file.split("/")[2].split('.')[0]
    root = tree.getroot()
    for ele in root.findall("./frame"):
        print("Frame:", ele.attrib["id"])
        file_name = "./text-file-norm/" + vid_num + "_" 
        file_name += "frame" + ele.attrib["id"] + ".txt"
        with open(file_name, "w") as file:
            for child in ele:
                class_name = fish_dict[child.attrib["fish_species"]]
                x = int(child.attrib["x"])
                y = int(child.attrib["y"])
                w = int(child.attrib["w"])
                h = int(child.attrib["h"])
                w_img = 640
                h_img = 480
                x = (x + w/2) / w_img
                y = (y + h/2) / h_img
                w = w / w_img
                h = h / h_img
                line = str(class_name) + " " + str(x) + " " + str(y) + " " + str(w) + " " + str(h)
                line += "\n"
                file.writelines(line)
                print(line)
        file.close()

import os
dir_path = "/content/drive/MyDrive/Fish detection/test/images/"
count=0
j=0
for i in os.listdir(dir_path):
  #print(i)
  if i == "tvid1_frame"+str(j)+".jpg":
    count+=1
    j += 1
print(count)

"""Draw Bounding box"""

from PIL import Image, ImageDraw


def yolo_to_xml_bbox(bbox, w, h):
    # x_center, y_center width heigth
    w_half_len = (bbox[2] * w) / 2
    h_half_len = (bbox[3] * h) / 2
    xmin = int((bbox[0] * w) - w_half_len)
    ymin = int((bbox[1] * h) - h_half_len)
    xmax = int((bbox[0] * w) + w_half_len)
    ymax = int((bbox[1] * h) + h_half_len)
    return [xmin, ymin, xmax, ymax]


def draw_image(img, bboxes):
    draw = ImageDraw.Draw(img)
    for bbox in bboxes:
        draw.rectangle(bbox, outline="red", width=2)
    img.save("example.jpg")
    img.show()


image_filename = "/content/drive/MyDrive/Fish_detection/train/images/vid10_frame33.jpg"
label_filename = "/content/drive/MyDrive/Fish_detection/train/labels/vid10_frame33.txt"
bboxes = []

img = Image.open(image_filename)

with open(label_filename, 'r', encoding='utf8') as f:
    for line in f:
        data = line.strip().split(' ')
        bbox = [float(x) for x in data[1:]]
        #print(bbox)
        #print(img.width)
        bboxes.append(yolo_to_xml_bbox(bbox, img.width, img.height))

draw_image(img, bboxes)

# Importing cv2
import cv2

# Path
for i in range(73):
  img = cv2.imread('/content/drive/MyDrive/Fish detection/test/images/tvid'+str(i+1)+'_frame11.jpg')
  # <class 'numpy.ndarray'>
  print('vid'+str(i+1)+': '+str(img.shape))

"""## **YoloR on big dataset**"""

# Commented out IPython magic to ensure Python compatibility.
# clone YOLOR repository
!git clone https://github.com/roboflow-ai/yolor
# %cd yolor
!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1

# Install necessary dependencies
!pip install -qr requirements.txt

# Commented out IPython magic to ensure Python compatibility.
# Install Mish CUDA
!git clone https://github.com/JunnYu/mish-cuda
# %cd mish-cuda
!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8
!python setup.py build install
# %cd ..

# Commented out IPython magic to ensure Python compatibility.
# Install PyTorch Wavelets
!git clone https://github.com/fbcotter/pytorch_wavelets
# %cd pytorch_wavelets
!pip install .
# %cd ..

# Commented out IPython magic to ensure Python compatibility.
data_loc="/content/drive/MyDrive/Fish_detection"
# %cat {data_loc}/data.yaml

#!rm yolor_p6.pt
#!rm yolor_w6.pt

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolor
! cp /content/drive/MyDrive/Fish_detection/yolor_p6.pt .
! cp /content/drive/MyDrive/Fish_detection/yolor_w6.pt .
!ls

import yaml
with open(data_loc + "/data.yaml") as f:
    dataMap = yaml.safe_load(f)

num_classes = len(dataMap['names'])
num_filters = (num_classes + 5) * 3
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# %%writetemplate /content/yolor/cfg/yolor_p6.cfg
# 
# [net]
# batch=64
# subdivisions=8
# width=1280
# height=1280
# channels=3
# momentum=0.949
# decay=0.0005
# angle=0
# saturation = 1.5
# exposure = 1.5
# hue=.1
# 
# learning_rate=0.00261
# burn_in=1000
# max_batches = 500500
# policy=steps
# steps=400000,450000
# scales=.1,.1
# 
# mosaic=1
# 
# 
# # ============ Backbone ============ #
# 
# # Stem 
# 
# # P1
# 
# # Downsample
# 
# # 0
# [reorg]
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=silu
# 
# 
# # P2
# 
# # Downsample
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=2
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Residual Block
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=64
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# # Transition first
# #
# #[convolutional]
# #batch_normalize=1
# #filters=64
# #size=1
# #stride=1
# #pad=1
# #activation=silu
# 
# # Merge [-1, -(3k+3)]
# 
# [route]
# layers = -1,-12
# 
# # Transition last
# 
# # 16 (previous+6+3k)
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # P3
# 
# # Downsample
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=2
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Residual Block
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# # Transition first
# #
# #[convolutional]
# #batch_normalize=1
# #filters=128
# #size=1
# #stride=1
# #pad=1
# #activation=silu
# 
# # Merge [-1, -(3k+3)]
# 
# [route]
# layers = -1,-24
# 
# # Transition last
# 
# # 43 (previous+6+3k)
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # P4
# 
# # Downsample
# 
# [convolutional]
# batch_normalize=1
# filters=384
# size=3
# stride=2
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Residual Block
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# # Transition first
# #
# #[convolutional]
# #batch_normalize=1
# #filters=192
# #size=1
# #stride=1
# #pad=1
# #activation=silu
# 
# # Merge [-1, -(3k+3)]
# 
# [route]
# layers = -1,-24
# 
# # Transition last
# 
# # 70 (previous+6+3k)
# [convolutional]
# batch_normalize=1
# filters=384
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # P5
# 
# # Downsample
# 
# [convolutional]
# batch_normalize=1
# filters=512
# size=3
# stride=2
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Residual Block
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# # Transition first
# #
# #[convolutional]
# #batch_normalize=1
# #filters=256
# #size=1
# #stride=1
# #pad=1
# #activation=silu
# 
# # Merge [-1, -(3k+3)]
# 
# [route]
# layers = -1,-12
# 
# # Transition last
# 
# # 85 (previous+6+3k)
# [convolutional]
# batch_normalize=1
# filters=512
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # P6
# 
# # Downsample
# 
# [convolutional]
# batch_normalize=1
# filters=640
# size=3
# stride=2
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Residual Block
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=3
# stride=1
# pad=1
# activation=silu
# 
# [shortcut]
# from=-3
# activation=linear
# 
# # Transition first
# #
# #[convolutional]
# #batch_normalize=1
# #filters=320
# #size=1
# #stride=1
# #pad=1
# #activation=silu
# 
# # Merge [-1, -(3k+3)]
# 
# [route]
# layers = -1,-12
# 
# # Transition last
# 
# # 100 (previous+6+3k)
# [convolutional]
# batch_normalize=1
# filters=640
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # ============ End of Backbone ============ #
# 
# # ============ Neck ============ #
# 
# # CSPSPP
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=320
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# ### SPP ###
# [maxpool]
# stride=1
# size=5
# 
# [route]
# layers=-2
# 
# [maxpool]
# stride=1
# size=9
# 
# [route]
# layers=-4
# 
# [maxpool]
# stride=1
# size=13
# 
# [route]
# layers=-1,-3,-5,-6
# ### End SPP ###
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=320
# activation=silu
# 
# [route]
# layers = -1, -13
# 
# # 115 (previous+6+5+2k)
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # End of CSPSPP
# 
# 
# # FPN-5
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [upsample]
# stride=2
# 
# [route]
# layers = 85
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -1, -3
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# # Merge [-1, -(2k+2)]
# 
# [route]
# layers = -1, -8
# 
# # Transition last
# 
# # 131 (previous+6+4+2k)
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # FPN-4
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [upsample]
# stride=2
# 
# [route]
# layers = 70
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -1, -3
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# # Merge [-1, -(2k+2)]
# 
# [route]
# layers = -1, -8
# 
# # Transition last
# 
# # 147 (previous+6+4+2k)
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # FPN-3
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [upsample]
# stride=2
# 
# [route]
# layers = 43
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -1, -3
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=128
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=128
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=128
# activation=silu
# 
# # Merge [-1, -(2k+2)]
# 
# [route]
# layers = -1, -8
# 
# # Transition last
# 
# # 163 (previous+6+4+2k)
# [convolutional]
# batch_normalize=1
# filters=128
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # PAN-4
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=2
# pad=1
# filters=192
# activation=silu
# 
# [route]
# layers = -1, 147
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=192
# activation=silu
# 
# [route]
# layers = -1,-8
# 
# # Transition last
# 
# # 176 (previous+3+4+2k)
# [convolutional]
# batch_normalize=1
# filters=192
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # PAN-5
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=2
# pad=1
# filters=256
# activation=silu
# 
# [route]
# layers = -1, 131
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [route]
# layers = -1,-8
# 
# # Transition last
# 
# # 189 (previous+3+4+2k)
# [convolutional]
# batch_normalize=1
# filters=256
# size=1
# stride=1
# pad=1
# activation=silu
# 
# 
# # PAN-6
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=2
# pad=1
# filters=320
# activation=silu
# 
# [route]
# layers = -1, 115
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # Split
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [route]
# layers = -2
# 
# # Plain Block
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=320
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=320
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=320
# activation=silu
# 
# [route]
# layers = -1,-8
# 
# # Transition last
# 
# # 202 (previous+3+4+2k)
# [convolutional]
# batch_normalize=1
# filters=320
# size=1
# stride=1
# pad=1
# activation=silu
# 
# # ============ End of Neck ============ #
# 
# # 203
# [implicit_add]
# filters=256
# 
# # 204
# [implicit_add]
# filters=384
# 
# # 205
# [implicit_add]
# filters=512
# 
# # 206
# [implicit_add]
# filters=640
# 
# # 207
# [implicit_mul]
# filters={num_filters}
# 
# # 208
# [implicit_mul]
# filters={num_filters}
# 
# # 209
# [implicit_mul]
# filters={num_filters}
# 
# # 210
# [implicit_mul]
# filters={num_filters}
# 
# # ============ Head ============ #
# 
# # YOLO-3
# 
# [route]
# layers = 163
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=256
# activation=silu
# 
# [shift_channels]
# from=203
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# [control_channels]
# from=207
# 
# [yolo]
# mask = 0,1,2
# anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792
# classes={num_classes}
# num=12
# jitter=.3
# ignore_thresh = .7
# truth_thresh = 1
# random=1
# scale_x_y = 1.05
# iou_thresh=0.213
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# nms_kind=greedynms
# beta_nms=0.6
# 
# 
# # YOLO-4
# 
# [route]
# layers = 176
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=384
# activation=silu
# 
# [shift_channels]
# from=204
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# [control_channels]
# from=208
# 
# [yolo]
# mask = 3,4,5
# anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792
# classes={num_classes}
# num=12
# jitter=.3
# ignore_thresh = .7
# truth_thresh = 1
# random=1
# scale_x_y = 1.05
# iou_thresh=0.213
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# nms_kind=greedynms
# beta_nms=0.6
# 
# 
# # YOLO-5
# 
# [route]
# layers = 189
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=512
# activation=silu
# 
# [shift_channels]
# from=205
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# [control_channels]
# from=209
# 
# [yolo]
# mask = 6,7,8
# anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792
# classes={num_classes}
# num=12
# jitter=.3
# ignore_thresh = .7
# truth_thresh = 1
# random=1
# scale_x_y = 1.05
# iou_thresh=0.213
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# nms_kind=greedynms
# beta_nms=0.6
# 
# 
# # YOLO-6
# 
# [route]
# layers = 202
# 
# [convolutional]
# batch_normalize=1
# size=3
# stride=1
# pad=1
# filters=640
# activation=silu
# 
# [shift_channels]
# from=206
# 
# [convolutional]
# size=1
# stride=1
# pad=1
# filters={num_filters}
# activation=linear
# 
# [control_channels]
# from=210
# 
# [yolo]
# mask = 9,10,11
# anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792
# classes={num_classes}
# num=12
# jitter=.3
# ignore_thresh = .7
# truth_thresh = 1
# random=1
# scale_x_y = 1.05
# iou_thresh=0.213
# cls_normalizer=1.0
# iou_normalizer=0.07
# iou_loss=ciou
# nms_kind=greedynms
# beta_nms=0.6
# 
# # ============ End of Head ============ #

# Commented out IPython magic to ensure Python compatibility.
# %cat /content/yolor/cfg/yolor_p6.cfg

"""Train Custom YOLOR Detector"""

!cp -r /content/drive/MyDrive/Fish_detection/valid /content/.

!cp -r /content/drive/MyDrive/Fish_detection/train /content/.

!rm /content/train/labels/vid7_frame*.txt
!rm /content/train/images/vid7_frame*.jpg

!rm /content/valid/labels_full/*
!rm /content/train/labels_full/*

!cp -r /content/drive/MyDrive/Fish_detection/test /content/.

#change this in utils/plots.py
'''
def output_to_target(output, width, height):
    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]
    targets = []
    for i, o in enumerate(output):
        if o is not None:
            if isinstance(o, torch.Tensor):
                o = o.cpu().numpy()
            for pred in o:
                box = pred[:4]
                w = (box[2] - box[0]) / width
                h = (box[3] - box[1]) / height
                x = box[0] / width + w / 2
                y = box[1] / height + h / 2
                conf = pred[4]
                cls = int(pred[5])

                targets.append([i, cls, x, y, w, h, conf])

    return np.array(targets)
  '''

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/yolor
!python train.py --batch-size 8 --img 416 416 --data {data_loc}/data.yaml --cfg cfg/yolor_p6.cfg --weights '/content/yolor/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 50

# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard
# Launch after you have started training
# logs save in the folder "runs"
# %load_ext tensorboard
# %tensorboard --logdir runs

!ls /content/yolor/runs/train/yolor_p6/weights

!cp /content/yolor/runs/train/yolor_p6/weights/best_overall.pt /content/drive/MyDrive/Fish_detection/yolor_conf50/
!cp /content/yolor/detect.py /content/drive/MyDrive/Fish_detection/yolor_conf50/
!cp /content/yolor/cfg/yolor_p6.cfg /content/drive/MyDrive/Fish_detection/yolor_conf50/

# Commented out IPython magic to ensure Python compatibility.
# trained weights are saved by default in our weights folder
# %ls runs/

# Commented out IPython magic to ensure Python compatibility.
# %ls runs/train/yolor_p64/weights

# Create names file for model
import yaml
import ast
with open("/content/drive/MyDrive/Fish_detection/data.yaml", 'r') as stream:
    names = str(yaml.safe_load(stream)['names'])

namesFile = open("../data.names", "w+")
names = ast.literal_eval(names)
for name in names:
  namesFile.write(name +'\n')
namesFile.close()

!cp -r /content/drive/MyDrive/Fish_detection/test /content/.

!cp /content/drive/MyDrive/Fish_detection/yolor_conf50/detect.py /content/
!cp /content/drive/MyDrive/Fish_detection/yolor_conf50/best_overall.pt /content/
!cp /content/drive/MyDrive/Fish_detection/yolor_conf50/yolor_p6.cfg /content/

!python /content/yolor/detect.py --weights "/content/best_overall.pt" --conf 0.5 --source /content/test/images --names ../data.names --cfg /content/yolor_p6.cfg > log_yolor.txt

!cd /content/yolor/
!python detect.py --weights "runs/train/yolor_p6/weights/best_overall.pt" --conf 0.5 --source ../test/images --names ../data.names --cfg cfg/yolor_p6.cfg > log.txt

#display inference on ALL test images
#this looks much better with longer training above

import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG
    display(Image(filename=imageName))
    print("\n")

"""Saving the weights"""

!cp /content/yolor/runs/train/yolor_p6/weights/best_overall.pt /content/drive/MyDrive/Fish_detection/yoloR_weights

!cp /content/yolor/cfg/yolor_p6.cfg /content/drive/MyDrive/Fish_detection/yoloR_weights
!cp /content/yolor/detect.py /content/drive/MyDrive/Fish_detection/yoloR_weights

